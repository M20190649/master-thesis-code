{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import (\n",
    "    Voronoi,\n",
    "    voronoi_plot_2d,\n",
    "    Delaunay,\n",
    "    delaunay_plot_2d,\n",
    "    cKDTree\n",
    ")\n",
    "import numpy as np\n",
    "import math, time\n",
    "import interpolators\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 30, 20\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"axes.titlesize\"] = 50\n",
    "plt.rcParams[\"axes.titlepad\"] = 80\n",
    "\n",
    "mode = \"raw\"\n",
    "\n",
    "def getMeasurementValue(value):\n",
    "    if math.isnan(value):\n",
    "        return 0\n",
    "\n",
    "    if mode == \"raw\":\n",
    "        return value\n",
    "\n",
    "    if mode == \"int\":\n",
    "        return int(value)\n",
    "\n",
    "    zones = [[0, 20], [20, 40], [40, 60], [60, math.inf]]\n",
    "    for i, zone in enumerate(zones):\n",
    "        zoneMin, zoneMax = zone\n",
    "        if value >= zoneMin and value < zoneMax:\n",
    "            return zoneMin\n",
    "\n",
    "def getPolygonsFromContour(contour):\n",
    "    polygons = []\n",
    "    for col in contour.collections:\n",
    "        # Loop through all polygons that have the same intensity level\n",
    "        for contour_path in col.get_paths():\n",
    "            # Create the polygon for this intensity level\n",
    "            # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "            for idx, poly_coords in enumerate(contour_path.to_polygons()):\n",
    "                x = poly_coords[:, 0]\n",
    "                y = poly_coords[:, 1]\n",
    "\n",
    "                new_shape = geometry.Polygon(\n",
    "                    [(point[0], point[1]) for point in zip(x, y)]\n",
    "                )\n",
    "                if idx == 0:\n",
    "                    poly = new_shape\n",
    "                else:\n",
    "                    # Remove the holes if there are any\n",
    "                    poly = poly.difference(new_shape)\n",
    "                    # Can also be left out if you want to include all rings\n",
    "\n",
    "            polygons.append(poly)\n",
    "    return polygons\n",
    "\n",
    "external_crs = \"EPSG:4326\"\n",
    "internal_crs = \"EPSG:3068\"\n",
    "berlinDistricts = gpd.read_file(\"../shared/berlinDistricts.geojson\")\n",
    "measurements = gpd.read_file(\"meeting-test/data_2020-03-02T14-00-00.geojson\")\n",
    "\n",
    "berlinDistricts = berlinDistricts.to_crs(internal_crs)\n",
    "measurements = measurements.to_crs(internal_crs)\n",
    "\n",
    "x = np.array(measurements.geometry.x)\n",
    "y = np.array(measurements.geometry.y)\n",
    "values = np.array(measurements.value)\n",
    "points = np.column_stack((x, y))\n",
    "\n",
    "xmin, ymin, xmax, ymax = measurements.total_bounds\n",
    "size = 500  # grid cell size in meters\n",
    "xnew = np.linspace(xmin, xmax, int((xmax - xmin) / size))\n",
    "ynew = np.linspace(ymin, ymax, int((ymax - ymin) / size))\n",
    "\n",
    "def plot_polygons(polygons):\n",
    "    fig, ax = plt.subplots()\n",
    "    for p in polygons:\n",
    "        plt.plot(*zip(*p.exterior.coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin Boundaries with Measurements\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Measurements\")\n",
    "berlinPlot = berlinDistricts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "measurements.plot(ax=ax, column=\"value\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin boundaries with interpolation grid\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Interpolation Grid\")\n",
    "berlinDistricts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "xx, yy = np.meshgrid(xnew,ynew)\n",
    "ax.scatter(xx, yy, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Voronoi diagram\n",
    "\n",
    "voronoi = Voronoi(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Voronoi Diagram\")\n",
    "berlinDistricts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "voronoi_plot_2d(voronoi, ax=ax, show_vertices=False, show_points=True, line_colors='orange')\n",
    "fig.savefig(\"voronoi.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Delauny diagram\n",
    "\n",
    "delauny = Delaunay(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Delauny Diagram\")\n",
    "berlinDistricts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "delaunay_plot_2d(delauny, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(list(zip(points[:,0], points[:, 1], values))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, random\n",
    "from scipy import interpolate\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "def ordinary_kriging(x, y, points, value): \n",
    "    \n",
    "    ok_interpolator = OrdinaryKriging(points[:, 0], points[:, 1], values, variogram_model='gaussian',\n",
    "                     verbose=True, enable_plotting=True)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    result = ok_interpolator.execute('grid', x, y)\n",
    "    print(result[0])\n",
    "    print(np.min(result[0]))\n",
    "    print(np.max(result[0]))\n",
    "    return result[0]\n",
    "\n",
    "def spline(x, y, points, values):\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    point_matrix = np.dstack((xx, yy))\n",
    "    tck = interpolate.bisplrep(points[:,0], points[:,1], values)\n",
    "    grid_values = interpolate.bisplev(xnew, ynew, tck).T\n",
    "    print(grid_values.shape)\n",
    "    return grid_values\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from geostatsmodels import utilities, kriging, variograms, model, geoplot\n",
    "from geostatsmodels.kriging import krige\n",
    "from scipy.stats import norm\n",
    "def kriging(x, y, points, values):\n",
    "    gpr = GaussianProcessRegressor(normalize_y=True)\n",
    "    gpr.fit(points, values)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    new_points = np.column_stack([xx.flatten(), yy.flatten()])\n",
    "    result = gpr.predict(new_points)\n",
    "    print(new_points.shape)\n",
    "    print(np.min(result))\n",
    "    print(np.max(result))\n",
    "    # return result.reshape(y.shape[0], x.shape[0])\n",
    "\n",
    "\n",
    "    x_point_dup = [\n",
    "        item for item, count in collections.Counter(points[:, 0]).items() if count > 1\n",
    "    ]\n",
    "    y_point_dup = [\n",
    "        item for item, count in collections.Counter(points[:, 1]).items() if count > 1\n",
    "    ]\n",
    "    fixed_x = list(\n",
    "        map(\n",
    "            lambda x: x + random.uniform(-0.00001, 0.00001) if x in x_point_dup else x,\n",
    "            points[:, 0],\n",
    "        )\n",
    "    )\n",
    "    fixed_y = list(\n",
    "        map(\n",
    "            lambda y: y + random.uniform(-0.00001, 0.00001) if y in y_point_dup else y,\n",
    "            points[:, 1],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fixed_points = np.column_stack((fixed_x, fixed_y))\n",
    "\n",
    "\n",
    "    tolerance = 250\n",
    "    lags = np.arange(tolerance, 10000, tolerance*2)\n",
    "    sill = np.var(values)\n",
    "    P = np.array(list(zip(fixed_points[:,0], fixed_points[:, 1], values)))\n",
    "    # geoplot.semivariogram(P, lags, tolerance)\n",
    "    svm = model.semivariance(model.spherical, (4000, sill))\n",
    "    # geoplot.semivariogram(P, lags, tolerance, model=svm)\n",
    "    covfct = model.covariance(model.spherical, (4000, sill))\n",
    "    # kriging.simple(P, covfct, pt, N=6)\n",
    "    est, kstd = krige(P, covfct, new_points, 'simple', N=6)\n",
    "\n",
    "\n",
    "def inverse_distance_weighting(x, y, points, values, p=2, k=6, grid=False):\n",
    "    # Credits to this guy: https://github.com/paulbrodersen/inverse_distance_weighting/blob/master/idw.py\n",
    "    tree = cKDTree(points, leafsize=10)\n",
    "    eps = 1e-6\n",
    "    regularize_by = 1e-9\n",
    "\n",
    "    if grid:\n",
    "        grid = np.meshgrid(x, y)\n",
    "        point_matrix = np.reshape(grid, (2, -1)).T\n",
    "    else:\n",
    "        point_matrix = np.column_stack((x, y))\n",
    "    print(point_matrix)\n",
    "\n",
    "    distances, idx = tree.query(point_matrix, k, eps=eps, p=p)\n",
    "\n",
    "    if len(idx.shape) == 1:\n",
    "        distances = np.atleast_2d(distances).reshape((-1, 1))\n",
    "        idx = np.atleast_2d(idx).reshape((-1, 1))\n",
    "\n",
    "    distances += regularize_by\n",
    "    neighbor_values = values[idx.ravel()].reshape(idx.shape)\n",
    "    summed_inverse_distances = np.sum(1 / distances, axis=1)\n",
    "    idw_values = np.sum(neighbor_values / distances, axis=1) / summed_inverse_distances\n",
    "    return idw_values.reshape(grid[0].shape)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# interpolated_values = interpolators.nearest_neighbor(xnew, ynew, points, values)\n",
    "interpolated_values = inverse_distance_weighting(xnew, ynew, points, values)\n",
    "# interpolated_values = rbf(xnew, ynew, points, values)\n",
    "# interpolated_values = kriging(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.linear_barycentric(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.natural_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.discrete_natural_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.inverse_distance_weighting(xnew, ynew, points, values, k=10)\n",
    "\n",
    "# interpolated_values = np.array([list(map(getMeasurementValue, row)) for row in interpolated_values])\n",
    "\n",
    "# print(interpolated_values.shape)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "berlinDistricts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "\n",
    "n_zones = 4\n",
    "zones = [0,20,40,100,200,400]\n",
    "plot = ax.contourf(xnew, ynew, interpolated_values, zones, cmap=\"winter_r\")\n",
    "plot.cmap.set_under('w')\n",
    "plot.set_clim(zones[1])\n",
    "\n",
    "# plot = ax.pcolormesh(xnew, ynew, interpolated_values)\n",
    "\n",
    "\n",
    "fig.colorbar(plot, ax=ax)\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(\"nn2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = getPolygonsFromContour(plot)[1:] # skip first because it covers all areas with zones as holes\n",
    "polygons = geopandas.GeoSeries(polygons)\n",
    "polygons.crs = internal_crs\n",
    "polygons = polygons.to_crs(external_crs)\n",
    "polygons.to_file(\"test.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import (\n",
    "    Voronoi,\n",
    "    voronoi_plot_2d,\n",
    "    Delaunay,\n",
    "    delaunay_plot_2d,\n",
    "    cKDTree\n",
    ")\n",
    "import numpy as np\n",
    "import math, time\n",
    "import interpolators\n",
    "\n",
    "measurements = geopandas.read_file(\"test/data_2020-02-20T00-30-00.geojson\")\n",
    "measurements = geopandas.read_file(\"test/data_2020-02-20T01-00-00.geojson\")\n",
    "np.sort(measurements.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "cmap = cm.get_cmap('viridis', 4)    # PiYG\n",
    "\n",
    "for i in range(cmap.N):\n",
    "    rgb = cmap(i)[:3] # will return rgba, we take only first 3 so we get rgb\n",
    "    # print(matplotlib.colors.rgb2hex(rgb))\n",
    "    print(\",\".join(list(map(str,rgb))))"
   ]
  }
 ]
}