{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import geometry\n",
    "from skimage import measure\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.spatial import (\n",
    "    Voronoi,\n",
    "    voronoi_plot_2d,\n",
    "    Delaunay,\n",
    "    delaunay_plot_2d,\n",
    "    cKDTree\n",
    ")\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import math, time, random\n",
    "import interpolators\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 30, 20\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"axes.titlesize\"] = 50\n",
    "plt.rcParams[\"axes.titlepad\"] = 80\n",
    "\n",
    "def get_polygons_per_zone_plt(xnew, ynew, interpolated_values, zones):\n",
    "    fig, ax = plt.subplots()\n",
    "    contour = ax.contourf(xnew, ynew, interpolated_values, zones, cmap=\"winter_r\")\n",
    "    plt.close()\n",
    "\n",
    "    polygons_per_zone = []\n",
    "\n",
    "    for col in contour.collections:\n",
    "        zone_polygons = []\n",
    "        # Loop through all polygons that have the same intensity level\n",
    "        for contour_path in col.get_paths():\n",
    "\n",
    "            # Create the polygon for this intensity level\n",
    "            # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "            poly = None\n",
    "            for idx, poly_coords in enumerate(contour_path.to_polygons()):\n",
    "                poly_coords = np.array(poly_coords)\n",
    "                x = poly_coords[:, 0]\n",
    "                y = poly_coords[:, 1]\n",
    "\n",
    "                new_shape = geometry.Polygon(\n",
    "                    [(point[0], point[1]) for point in zip(x, y)]\n",
    "                )\n",
    "\n",
    "                if idx == 0:\n",
    "                    poly = new_shape\n",
    "                else:\n",
    "                    # Remove the holes if there are any\n",
    "                    poly = poly.difference(new_shape)\n",
    "                    # Can also be left out if you want to include all rings\n",
    "\n",
    "            if poly is not None:\n",
    "                zone_polygons.append(poly)\n",
    "        polygons_per_zone.append(zone_polygons)\n",
    "    return polygons_per_zone\n",
    "\n",
    "def get_polygons_per_zone(xnew, ynew, interpolated_values, zones):\n",
    "    xmin = np.min(xnew)\n",
    "    xmax = np.max(xnew)\n",
    "    ymin = np.min(ynew)\n",
    "    ymax = np.max(ynew)\n",
    "    scale_x = lambda x: xmin + (xmax-xmin)/len(xnew)*(x+0.5)\n",
    "    scale_y = lambda y: ymin + (ymax-ymin)/len(ynew)*(y+0.5)\n",
    "\n",
    "    polygons_per_zone = []\n",
    "\n",
    "    # Iterate in reverse to go from most inner zones to outer zones\n",
    "    # Makes it easier for hole detections\n",
    "    for zone, zone_limit in enumerate(zones[::-1]):\n",
    "        contours = measure.find_contours(interpolated_values, zone_limit)\n",
    "        contour_polygons = list(map(lambda c: geometry.Polygon(zip(scale_x(c[:, 1]), scale_y(c[:, 0]))), contours))\n",
    "        \n",
    "        previous_polygons = list(itertools.chain(*polygons_per_zone))\n",
    "        zone_polygons = []\n",
    "        holes = []\n",
    "\n",
    "        for p1 in contour_polygons:\n",
    "            if p1 in holes:\n",
    "                continue\n",
    "\n",
    "            # Check for holes in this current contour\n",
    "            for p2 in contour_polygons:\n",
    "                if p1 == p2:\n",
    "                    continue\n",
    "\n",
    "                if p1.contains(p2):\n",
    "                    p1 = p1.difference(p2)\n",
    "                    holes.append(p2)\n",
    "            \n",
    "            # Check if inner contours are holes in current polygon\n",
    "            for p2 in previous_polygons:\n",
    "                if p1.contains(p2):\n",
    "                    p1 = p1.difference(p2)\n",
    "                    holes.append(p2)\n",
    "            \n",
    "            zone_polygons.append(p1)\n",
    "        polygons_per_zone.append(zone_polygons)\n",
    "    # Reverse again to return polygons in same order as input zones\n",
    "    return polygons_per_zone[::-1]\n",
    "\n",
    "def plot_polygons(polygons):\n",
    "    polygon_df = gpd.GeoDataFrame()\n",
    "    for polygon in polygons:\n",
    "        temp_df = gpd.GeoDataFrame({\"geometry\": [polygon]})\n",
    "        polygon_df = pd.concat([polygon_df, temp_df])\n",
    "    polygon_df.plot()\n",
    "\n",
    "def get_cmap_colors(cmap_name, n, rgb=True):\n",
    "    cmap = cm.get_cmap(cmap_name, n)    # PiYG\n",
    "\n",
    "    colors = []\n",
    "    for i in range(cmap.N):\n",
    "        rgb_values = cmap(i)[:3] # will return rgba, we take only first 3 so we get rgb\n",
    "        if rgb:\n",
    "            colors.append(\",\".join(list(map(str,rgb_values))))\n",
    "        else:\n",
    "            colors.append(mpl.colors.rgb2hex(rgb_values))\n",
    "    return colors\n",
    "\n",
    "external_crs = \"EPSG:4326\"\n",
    "internal_crs = \"EPSG:3068\"\n",
    "berlin_districts = gpd.read_file(\"../shared/berlinDistricts.geojson\")\n",
    "# measurements = gpd.read_file(\"raw-test/data_2020-02-12T14-00-00.geojson\")\n",
    "# measurements = gpd.read_file(\"meeting-test/data_2020-03-02T22-00-00.geojson\")\n",
    "# measurements = gpd.read_file(\"meeting-test/data_2020-03-02T03-00-00.geojson\")\n",
    "measurements = gpd.read_file(\"backup/data_2020-02-02T21-00-00.geojson\")\n",
    "\n",
    "berlin_districts = berlin_districts.to_crs(internal_crs)\n",
    "measurements = measurements.to_crs(internal_crs)\n",
    "\n",
    "x = np.array(measurements.geometry.x)\n",
    "y = np.array(measurements.geometry.y)\n",
    "values = np.array(measurements.value)\n",
    "points = np.column_stack((x, y))\n",
    "\n",
    "xmin, ymin, xmax, ymax = berlin_districts.total_bounds\n",
    "size = 100  # grid cell size in meters\n",
    "xnew = np.linspace(xmin, xmax, int((xmax - xmin) / size))\n",
    "ynew = np.linspace(ymin, ymax, int((ymax - ymin) / size))\n",
    "zones = [0, 20, 35, 50, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def kernel_regression(x, y, points, values, grid=True, k=None, kernel=\"gaussian\"):\n",
    "    points = interpolators.regularize_points(points)\n",
    "\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    if grid:\n",
    "        meshgrid = np.meshgrid(x, y)\n",
    "        point_matrix = np.reshape(meshgrid, (2, -1)).T\n",
    "    else:\n",
    "        point_matrix = np.column_stack((x, y))\n",
    "\n",
    "    kr = KernelRidge(kernel=\"rbf\")\n",
    "    kr.fit(points, values)\n",
    "    y_kr = kr.predict(point_matrix)\n",
    "\n",
    "    y_kr = y_kr.reshape(meshgrid[0].shape)\n",
    "    print(y_kr)\n",
    "    print(y_kr.shape)\n",
    "\n",
    "    return y_kr\n",
    "\n",
    "\n",
    "    k = k or len(points)\n",
    "    distances, idx = tree.query(point_matrix, k=k)\n",
    "\n",
    "    if len(idx.shape) == 1:\n",
    "        distances = np.atleast_2d(distances).reshape((-1, 1))\n",
    "        idx = np.atleast_2d(idx).reshape((-1, 1))\n",
    "\n",
    "    bandwidth = 0.1\n",
    "    # distances = distances / bandwidth\n",
    "    \n",
    "    kernels = {\n",
    "        \"gaussian\": lambda x: 1 / np.sqrt(2 * np.pi) * np.exp(-x ** 2 / 2),\n",
    "        \"cauchy\": 1,\n",
    "        \"epanechnikov\": 1,\n",
    "        \"uniform\": 1\n",
    "    }\n",
    "\n",
    "    weights = kernels[kernel](distances)\n",
    "    weights_sum = np.sum(weights, axis=1)\n",
    "    neighbor_values = values[idx.ravel()].reshape(idx.shape)\n",
    "    \n",
    "    estimation = np.sum(weights * neighbor_values, axis=1) / weights_sum\n",
    "\n",
    "    print(np.max(weights))\n",
    "\n",
    "    print(estimation)\n",
    "\n",
    "    if grid:\n",
    "        return estimation.reshape(meshgrid[0].shape)\n",
    "    else:\n",
    "        return estimation\n",
    "\n",
    "kernel_regression(xnew, ynew, points, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_values = interpolators.nearest_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.natural_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.discrete_natural_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.inverse_distance_weighting(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.radial_basis_function(xnew, ynew, points, values, function=\"linear\")\n",
    "# interpolated_values = interpolators.kriging(xnew, ynew, points, values, krige_type=\"ordinary\", nlags=100)\n",
    "\n",
    "interpolated_values = kernel_regression(xnew, ynew, points, values)\n",
    "\n",
    "print(interpolated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# polygons_per_zone = get_polygons_per_zone_plt(xnew, ynew, interpolated_values, zones)\n",
    "polygons_per_zone = get_polygons_per_zone(xnew, ynew, interpolated_values, zones)\n",
    "print(time.time()-start)\n",
    "\n",
    "for x in polygons_per_zone:\n",
    "    print(len(x))\n",
    "\n",
    "# print(polygons_per_zone)\n",
    "# plot_polygons(polygons_per_zone[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin Boundaries with Measurements\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Measurements\")\n",
    "# ax.get_xaxis().set_visible(False)\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "berlinPlot = berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "measurements.plot(ax=ax, column=\"value\", legend=True, cmap=\"winter_r\", markersize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin boundaries with interpolation grid\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Interpolation Grid\")\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "xx, yy = np.meshgrid(xnew,ynew)\n",
    "ax.scatter(xx, yy, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Voronoi diagram\n",
    "\n",
    "voronoi = Voronoi(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"gray\")\n",
    "voronoi_plot_2d(voronoi, ax=ax, show_vertices=False, show_points=False, line_colors='black', line_width=1.5)\n",
    "measurements.plot(ax=ax, column=\"value\", legend=True, cmap=\"winter_r\", markersize=50)\n",
    "\n",
    "# ax.set_title(\"Berlin Districts with Voronoi Diagram\")\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_xlim([15000,21000])\n",
    "ax.set_ylim([18000,23000])\n",
    "\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"voronoi.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Delauny diagram\n",
    "\n",
    "delauny = Delaunay(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Delauny Diagram\")\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "delaunay_plot_2d(delauny, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.hist(values)\n",
    "ax.hist(scale(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variogram Cloud\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "p_distances = pdist(points)\n",
    "\n",
    "v_distances = 1/2 * (pdist(values.reshape(-1, 1)) ** 2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(p_distances, v_distances)\n",
    "ax.set_xlabel(\"h (lag)\", fontsize=20)\n",
    "ax.set_ylabel(r'$\\gamma(h)$', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of value distances\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(v_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental Variogram\n",
    "\n",
    "bins = 10\n",
    "n, bin_edges = np.histogram(p_distances, bins=bins)\n",
    "summed_distances_per_bin, bin_edges = np.histogram(p_distances, bins=bins, weights=v_distances)\n",
    "mean = summed_distances_per_bin / n\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter((bin_edges[1:] + bin_edges[:-1])/2, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolated grid points in color\n",
    "\n",
    "grid = np.meshgrid(xnew, ynew)\n",
    "new_points = np.reshape(grid, (2, -1)).T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "berlinPlot = berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "scatter = ax.scatter(new_points[:,0], new_points[:,1], s=1, c=interpolated_values.ravel(), cmap=\"winter_r\")\n",
    "scatter.cmap.set_under(\"w\")\n",
    "plt.colorbar(scatter)\n",
    "# fig.set_size_inches(30*2, 20*2)\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"interpolated-grid.png\", bbox_inches='tight')\n",
    "# scatter.set_clim(zones[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colored grid with interpolation as image\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(interpolated_values, origin=\"lower\", cmap=\"Reds\", extent=[xmin, xmax, ymin, ymax])\n",
    "img.cmap.set_under(\"w\")\n",
    "img.set_clim(zones[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours using matplotlib\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "\n",
    "contour = ax.contour(xnew, ynew, interpolated_values, zones, linewidths=1)\n",
    "contourf = ax.contourf(xnew, ynew, interpolated_values, zones[0:-1], cmap=\"winter_r\")\n",
    "\n",
    "contourf.cmap.set_under(\"w\")\n",
    "contourf.set_clim(zones[1])\n",
    "fig.colorbar(contourf, ax=ax)\n",
    "\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"extracted-zones.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours using skimage and marching squares\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "\n",
    "img = ax.imshow(interpolated_values, origin=\"lower\", cmap=\"winter_r\", extent=[xmin, xmax, ymin, ymax])\n",
    "img.cmap.set_under(\"w\")\n",
    "img.set_clim(zones[1])\n",
    "\n",
    "scale_x = lambda x: xmin + (xmax-xmin)/len(xnew)*(x+0.5)\n",
    "scale_y = lambda y: ymin + (ymax-ymin)/len(ynew)*(y+0.5)\n",
    "\n",
    "colors = get_cmap_colors(\"winter_r\", len(zones))\n",
    "for i, zone in enumerate(zones):\n",
    "    contours = measure.find_contours(interpolated_values, zone)\n",
    "    color = tuple(map(float, colors[i].split(\",\")))\n",
    "    print(color)\n",
    "    for n, contour in enumerate(contours):\n",
    "        ax.plot(scale_x(contour[:, 1]), scale_y(contour[:, 0]), linewidth=1, color=color)\n",
    "\n",
    "fig.colorbar(img)\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"extracted-zones.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "\n",
    "def kriging(x, y, points, values, nlags=10, cv=False, krige_type=\"ordinary\"):\n",
    "    points = interpolators.regularize_points(points)\n",
    "\n",
    "    if cv:\n",
    "        print(\"Doing CV to determine best number of lags...\")\n",
    "        folds = 10\n",
    "        seed = random.randint(0,9999)\n",
    "        kfold = KFold(folds, True, seed)\n",
    "        avg_rmse_per_lag = {}\n",
    "        for lags in range(2, 101):\n",
    "            sum_rmse = 0\n",
    "            for train, test in kfold.split(values):\n",
    "                train_points = points[train]\n",
    "                train_values = values[train]\n",
    "                test_points = points[test]\n",
    "                test_values = values[test]\n",
    "\n",
    "                krige_interpolator = None\n",
    "                if krige_type == \"ordinary\":\n",
    "                    krige_interpolator = OrdinaryKriging(train_points[:, 0], train_points[:, 1], train_values, nlags=lags)\n",
    "                \n",
    "                if krige_type == \"universal\":\n",
    "                    krige_interpolator = OrdinaryKriging(train_points[:, 0], train_points[:, 1], train_values, nlags=lags) \n",
    "\n",
    "                result = krige_interpolator.execute('points', test_points[:, 0], test_points[:, 1])\n",
    "                rmse = mean_squared_error(test_values, result[0])\n",
    "                sum_rmse +=rmse\n",
    "            \n",
    "            avg_rmse = sum_rmse/folds\n",
    "            avg_rmse_per_lag[lags] = avg_rmse\n",
    "\n",
    "        print(\"Done\")\n",
    "        nlags = min(avg_rmse_per_lag, key=avg_rmse_per_lag.get)\n",
    "        print(f\"Winning lag: {nlags}\")\n",
    "        print(f\"Avg RMSE: {avg_rmse_per_lag[nlags]}\")\n",
    "\n",
    "    krige_interpolator = None\n",
    "    if krige_type == \"ordinary\":\n",
    "        krige_interpolator = OrdinaryKriging(points[:, 0], points[:, 1], values, nlags=nlags, verbose=True)\n",
    "\n",
    "    if krige_type == \"universal\":\n",
    "        krige_interpolator = OrdinaryKriging(points[:, 0], points[:, 1], values, nlags=nlags, verbose=True) \n",
    "\n",
    "    krige_interpolator.display_variogram_model()\n",
    "\n",
    "    result = krige_interpolator.execute('grid', x, y)\n",
    "    return result[0]\n",
    "\n",
    "interpolated_values = kriging(xnew, ynew, points, values)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}