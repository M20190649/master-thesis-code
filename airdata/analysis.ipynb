{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import geometry\n",
    "from skimage import measure\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.spatial import (\n",
    "    Voronoi,\n",
    "    voronoi_plot_2d,\n",
    "    Delaunay,\n",
    "    delaunay_plot_2d,\n",
    "    cKDTree\n",
    ")\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import math, time, random\n",
    "import interpolators\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 30, 20\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"axes.titlesize\"] = 50\n",
    "plt.rcParams[\"axes.titlepad\"] = 80\n",
    "\n",
    "def get_polygons_per_zone_plt(xnew, ynew, interpolated_values, zones):\n",
    "    fig, ax = plt.subplots()\n",
    "    contour = ax.contourf(xnew, ynew, interpolated_values, zones, cmap=\"winter_r\")\n",
    "    plt.close()\n",
    "\n",
    "    polygons_per_zone = []\n",
    "\n",
    "    for col in contour.collections:\n",
    "        zone_polygons = []\n",
    "        # Loop through all polygons that have the same intensity level\n",
    "        for contour_path in col.get_paths():\n",
    "\n",
    "            # Create the polygon for this intensity level\n",
    "            # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "            poly = None\n",
    "            for idx, poly_coords in enumerate(contour_path.to_polygons()):\n",
    "                poly_coords = np.array(poly_coords)\n",
    "                x = poly_coords[:, 0]\n",
    "                y = poly_coords[:, 1]\n",
    "\n",
    "                new_shape = geometry.Polygon(\n",
    "                    [(point[0], point[1]) for point in zip(x, y)]\n",
    "                )\n",
    "\n",
    "                if idx == 0:\n",
    "                    poly = new_shape\n",
    "                else:\n",
    "                    # Remove the holes if there are any\n",
    "                    poly = poly.difference(new_shape)\n",
    "                    # Can also be left out if you want to include all rings\n",
    "\n",
    "            if poly is not None:\n",
    "                zone_polygons.append(poly)\n",
    "        polygons_per_zone.append(zone_polygons)\n",
    "    return polygons_per_zone\n",
    "\n",
    "def get_polygons_per_zone(xnew, ynew, interpolated_values, zones):\n",
    "    xmin = np.min(xnew)\n",
    "    xmax = np.max(xnew)\n",
    "    ymin = np.min(ynew)\n",
    "    ymax = np.max(ynew)\n",
    "    scale_x = lambda x: xmin + (xmax-xmin)/len(xnew)*(x+0.5)\n",
    "    scale_y = lambda y: ymin + (ymax-ymin)/len(ynew)*(y+0.5)\n",
    "\n",
    "    polygons_per_zone = []\n",
    "\n",
    "    # Iterate in reverse to go from most inner zones to outer zones\n",
    "    # Makes it easier for hole detections\n",
    "    for zone, zone_limit in enumerate(zones[::-1]):\n",
    "        contours = measure.find_contours(interpolated_values, zone_limit)\n",
    "        contour_polygons = list(map(lambda c: geometry.Polygon(zip(scale_x(c[:, 1]), scale_y(c[:, 0]))), contours))\n",
    "        \n",
    "        previous_polygons = list(itertools.chain(*polygons_per_zone))\n",
    "        zone_polygons = []\n",
    "        holes = []\n",
    "\n",
    "        for p1 in contour_polygons:\n",
    "            if p1 in holes:\n",
    "                continue\n",
    "\n",
    "            # Check for holes in this current contour\n",
    "            for p2 in contour_polygons:\n",
    "                if p1 == p2:\n",
    "                    continue\n",
    "\n",
    "                if p1.contains(p2):\n",
    "                    print(p1)\n",
    "                    print(p2)\n",
    "                    p1 = p1.difference(p2)\n",
    "                    holes.append(p2)\n",
    "            \n",
    "            # Check if inner contours are holes in current polygon\n",
    "            for p2 in previous_polygons:\n",
    "                if p1.contains(p2):\n",
    "                    p1 = p1.difference(p2)\n",
    "                    holes.append(p2)\n",
    "            \n",
    "            zone_polygons.append(p1)\n",
    "        polygons_per_zone.append(zone_polygons)\n",
    "    # Reverse again to return polygons in same order as input zones\n",
    "    return polygons_per_zone[::-1]\n",
    "\n",
    "def plot_polygons(polygons):\n",
    "    polygon_df = gpd.GeoDataFrame()\n",
    "    for polygon in polygons:\n",
    "        temp_df = gpd.GeoDataFrame({\"geometry\": [polygon]})\n",
    "        polygon_df = pd.concat([polygon_df, temp_df])\n",
    "    polygon_df.plot()\n",
    "\n",
    "def get_cmap_colors(cmap_name, n, rgb=True):\n",
    "    cmap = cm.get_cmap(cmap_name, n)    # PiYG\n",
    "\n",
    "    colors = []\n",
    "    for i in range(cmap.N):\n",
    "        rgb_values = cmap(i)[:3] # will return rgba, we take only first 3 so we get rgb\n",
    "        if rgb:\n",
    "            colors.append(\",\".join(list(map(str,rgb_values))))\n",
    "        else:\n",
    "            colors.append(mpl.colors.rgb2hex(rgb_values))\n",
    "    return colors\n",
    "\n",
    "external_crs = \"EPSG:4326\"\n",
    "internal_crs = \"EPSG:3068\"\n",
    "berlin_districts = gpd.read_file(\"../shared/berlinDistricts.geojson\")\n",
    "# measurements = gpd.read_file(\"raw-test/data_2020-02-12T14-00-00.geojson\")\n",
    "# measurements = gpd.read_file(\"meeting-test/data_2020-03-02T22-00-00.geojson\")\n",
    "# measurements = gpd.read_file(\"meeting-test/data_2020-03-02T03-00-00.geojson\")\n",
    "measurements = gpd.read_file(\"01-02-2020/data_2020-02-01T03-00-00.geojson\")\n",
    "\n",
    "berlin_districts = berlin_districts.to_crs(internal_crs)\n",
    "measurements = measurements.to_crs(internal_crs)\n",
    "\n",
    "x = np.array(measurements.geometry.x)\n",
    "y = np.array(measurements.geometry.y)\n",
    "values = np.array(measurements.value)\n",
    "points = np.column_stack((x, y))\n",
    "\n",
    "xmin, ymin, xmax, ymax = berlin_districts.total_bounds\n",
    "size = 100  # grid cell size in meters\n",
    "xnew = np.linspace(xmin, xmax, int((xmax - xmin) / size))\n",
    "ynew = np.linspace(ymin, ymax, int((ymax - ymin) / size))\n",
    "zones = [0, 20, 35, 50, 100, 10000]\n",
    "\n",
    "distance = 500\n",
    "max_diff = 100\n",
    "remove_idx = []\n",
    "tree = cKDTree(points)\n",
    "for point_idx, point in enumerate(points):\n",
    "    distances, neighbor_idx = tree.query(point, k=len(points), distance_upper_bound=distance)\n",
    "    for i in neighbor_idx:\n",
    "        if i == len(points):\n",
    "            continue\n",
    "        \n",
    "        point_value = values[point_idx]\n",
    "        neighbor_value = values[i]\n",
    "        diff = np.abs(point_value - neighbor_value)\n",
    "        if diff > max_diff and point_value > neighbor_value:\n",
    "            remove_idx.append(point_idx)\n",
    "            \n",
    "points = np.delete(points, remove_idx, axis=0)\n",
    "values = np.delete(values, remove_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def kernel_regression(x, y, points, values, grid=True, k=None, kernel=\"gaussian\"):\n",
    "    points = interpolators.regularize_points(points)\n",
    "\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    if grid:\n",
    "        meshgrid = np.meshgrid(x, y)\n",
    "        point_matrix = np.reshape(meshgrid, (2, -1)).T\n",
    "    else:\n",
    "        point_matrix = np.column_stack((x, y))\n",
    "\n",
    "    kr = KernelRidge(kernel=\"rbf\")\n",
    "    kr.fit(points, values)\n",
    "    y_kr = kr.predict(point_matrix)\n",
    "\n",
    "    y_kr = y_kr.reshape(meshgrid[0].shape)\n",
    "    print(y_kr)\n",
    "    print(y_kr.shape)\n",
    "\n",
    "    return y_kr\n",
    "\n",
    "\n",
    "    k = k or len(points)\n",
    "    distances, idx = tree.query(point_matrix, k=k)\n",
    "\n",
    "    if len(idx.shape) == 1:\n",
    "        distances = np.atleast_2d(distances).reshape((-1, 1))\n",
    "        idx = np.atleast_2d(idx).reshape((-1, 1))\n",
    "\n",
    "    bandwidth = 0.1\n",
    "    # distances = distances / bandwidth\n",
    "    \n",
    "    kernels = {\n",
    "        \"gaussian\": lambda x: 1 / np.sqrt(2 * np.pi) * np.exp(-x ** 2 / 2),\n",
    "        \"cauchy\": 1,\n",
    "        \"epanechnikov\": 1,\n",
    "        \"uniform\": 1\n",
    "    }\n",
    "\n",
    "    weights = kernels[kernel](distances)\n",
    "    weights_sum = np.sum(weights, axis=1)\n",
    "    neighbor_values = values[idx.ravel()].reshape(idx.shape)\n",
    "    \n",
    "    estimation = np.sum(weights * neighbor_values, axis=1) / weights_sum\n",
    "\n",
    "    print(np.max(weights))\n",
    "\n",
    "    print(estimation)\n",
    "\n",
    "    if grid:\n",
    "        return estimation.reshape(meshgrid[0].shape)\n",
    "    else:\n",
    "        return estimation\n",
    "\n",
    "kernel_regression(xnew, ynew, points, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_values = interpolators.nearest_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.natural_neighbor(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.discrete_natural_neighbor(xnew, ynew, points, values)\n",
    "interpolated_values = interpolators.inverse_distance_weighting(xnew, ynew, points, values)\n",
    "# interpolated_values = interpolators.radial_basis_function(xnew, ynew, points, values, function=\"linear\")\n",
    "# interpolated_values = interpolators.kriging(xnew, ynew, points, values, krige_type=\"ordinary\", nlags=100)\n",
    "\n",
    "# interpolated_values = kernel_regression(xnew, ynew, points, values)\n",
    "\n",
    "print(interpolated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "polygons_per_zone = get_polygons_per_zone_plt(xnew, ynew, interpolated_values, zones)\n",
    "# polygons_per_zone = get_polygons_per_zone(xnew, ynew, interpolated_values, zones)\n",
    "print(time.time()-start)\n",
    "\n",
    "for x in polygons_per_zone:\n",
    "    print(len(x))\n",
    "\n",
    "# print(polygons_per_zone)\n",
    "# plot_polygons(polygons_per_zone[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin Boundaries with Measurements\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Measurements\")\n",
    "# ax.get_xaxis().set_visible(False)\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "berlinPlot = berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "measurements.plot(ax=ax, column=\"value\", legend=True, cmap=\"winter_r\", markersize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin boundaries with interpolation grid\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Interpolation Grid\")\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "xx, yy = np.meshgrid(xnew,ynew)\n",
    "ax.scatter(xx, yy, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Voronoi diagram\n",
    "\n",
    "voronoi = Voronoi(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"gray\")\n",
    "voronoi_plot_2d(voronoi, ax=ax, show_vertices=False, show_points=False, line_colors='black', line_width=1.5)\n",
    "measurements.plot(ax=ax, column=\"value\", legend=True, cmap=\"winter_r\", markersize=50)\n",
    "\n",
    "# ax.set_title(\"Berlin Districts with Voronoi Diagram\")\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_xlim([15000,21000])\n",
    "ax.set_ylim([18000,23000])\n",
    "\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"voronoi.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Berlin with Delauny diagram\n",
    "\n",
    "delauny = Delaunay(points)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Berlin Districts with Delauny Diagram\")\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "delaunay_plot_2d(delauny, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.hist(values)\n",
    "ax.hist(scale(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variogram Cloud\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "p_distances = pdist(points)\n",
    "\n",
    "v_distances = 1/2 * (pdist(values.reshape(-1, 1)) ** 2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(p_distances, v_distances)\n",
    "ax.set_xlabel(\"h (lag)\", fontsize=20)\n",
    "ax.set_ylabel(r'$\\gamma(h)$', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of value distances\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(v_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental Variogram\n",
    "\n",
    "bins = 10\n",
    "n, bin_edges = np.histogram(p_distances, bins=bins)\n",
    "summed_distances_per_bin, bin_edges = np.histogram(p_distances, bins=bins, weights=v_distances)\n",
    "mean = summed_distances_per_bin / n\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter((bin_edges[1:] + bin_edges[:-1])/2, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolated grid points in color\n",
    "\n",
    "grid = np.meshgrid(xnew, ynew)\n",
    "new_points = np.reshape(grid, (2, -1)).T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "berlinPlot = berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "scatter = ax.scatter(new_points[:,0], new_points[:,1], s=1, c=interpolated_values.ravel(), cmap=\"winter_r\")\n",
    "scatter.cmap.set_under(\"w\")\n",
    "plt.colorbar(scatter)\n",
    "# fig.set_size_inches(30*2, 20*2)\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"interpolated-grid.png\", bbox_inches='tight')\n",
    "# scatter.set_clim(zones[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colored grid with interpolation as image\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(interpolated_values, origin=\"lower\", cmap=\"Reds\", extent=[xmin, xmax, ymin, ymax])\n",
    "img.cmap.set_under(\"w\")\n",
    "img.set_clim(zones[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours using matplotlib\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "\n",
    "contour = ax.contour(xnew, ynew, interpolated_values, zones, linewidths=1)\n",
    "colors = [\"w\", *get_cmap_colors(\"winter_r\", len(zones) - 1, False)]\n",
    "contourf = ax.contourf(xnew, ynew, interpolated_values, zones, colors=colors)\n",
    "\n",
    "fig.colorbar(contourf, ax=ax)\n",
    "\n",
    "fig.set_dpi(100)\n",
    "# fig.savefig(\"extracted-zones.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours using skimage and marching squares\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "berlin_districts.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "\n",
    "img = ax.imshow(interpolated_values, origin=\"lower\", cmap=\"winter_r\", extent=[xmin, xmax, ymin, ymax])\n",
    "img.cmap.set_under(\"w\")\n",
    "img.set_clim(zones[1])\n",
    "\n",
    "scale_x = lambda x: xmin + (xmax-xmin)/len(xnew)*(x+0.5)\n",
    "scale_y = lambda y: ymin + (ymax-ymin)/len(ynew)*(y+0.5)\n",
    "\n",
    "colors = get_cmap_colors(\"winter_r\", len(zones))\n",
    "for i, zone in enumerate(zones):\n",
    "    contours = measure.find_contours(interpolated_values, zone)\n",
    "    color = tuple(map(float, colors[i].split(\",\")))\n",
    "    print(color)\n",
    "    for n, contour in enumerate(contours):\n",
    "        ax.plot(scale_x(contour[:, 1]), scale_y(contour[:, 0]), linewidth=1, color=color)\n",
    "\n",
    "fig.colorbar(img)\n",
    "fig.set_dpi(100)\n",
    "fig.savefig(\"extracted-zones.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "\n",
    "def kriging(x, y, points, values, nlags=10, cv=False, krige_type=\"ordinary\"):\n",
    "    points = interpolators.regularize_points(points)\n",
    "\n",
    "    if cv:\n",
    "        print(\"Doing CV to determine best number of lags...\")\n",
    "        folds = 10\n",
    "        seed = random.randint(0,9999)\n",
    "        kfold = KFold(folds, True, seed)\n",
    "        avg_rmse_per_lag = {}\n",
    "        for lags in range(2, 101):\n",
    "            sum_rmse = 0\n",
    "            for train, test in kfold.split(values):\n",
    "                train_points = points[train]\n",
    "                train_values = values[train]\n",
    "                test_points = points[test]\n",
    "                test_values = values[test]\n",
    "\n",
    "                krige_interpolator = None\n",
    "                if krige_type == \"ordinary\":\n",
    "                    krige_interpolator = OrdinaryKriging(train_points[:, 0], train_points[:, 1], train_values, nlags=lags)\n",
    "                \n",
    "                if krige_type == \"universal\":\n",
    "                    krige_interpolator = OrdinaryKriging(train_points[:, 0], train_points[:, 1], train_values, nlags=lags) \n",
    "\n",
    "                result = krige_interpolator.execute('points', test_points[:, 0], test_points[:, 1])\n",
    "                rmse = mean_squared_error(test_values, result[0])\n",
    "                sum_rmse +=rmse\n",
    "            \n",
    "            avg_rmse = sum_rmse/folds\n",
    "            avg_rmse_per_lag[lags] = avg_rmse\n",
    "\n",
    "        print(\"Done\")\n",
    "        nlags = min(avg_rmse_per_lag, key=avg_rmse_per_lag.get)\n",
    "        print(f\"Winning lag: {nlags}\")\n",
    "        print(f\"Avg RMSE: {avg_rmse_per_lag[nlags]}\")\n",
    "\n",
    "    krige_interpolator = None\n",
    "    if krige_type == \"ordinary\":\n",
    "        krige_interpolator = OrdinaryKriging(points[:, 0], points[:, 1], values, nlags=nlags, verbose=True)\n",
    "\n",
    "    if krige_type == \"universal\":\n",
    "        krige_interpolator = OrdinaryKriging(points[:, 0], points[:, 1], values, nlags=nlags, verbose=True) \n",
    "\n",
    "    krige_interpolator.display_variogram_model()\n",
    "\n",
    "    result = krige_interpolator.execute('grid', x, y)\n",
    "    return result[0]\n",
    "\n",
    "interpolated_values = kriging(xnew, ynew, points, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jake Vanderplas <jakevdp@cs.washington.edu>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# if basemap is available, we'll use it.\n",
    "# otherwise, we'll improvise later...\n",
    "try:\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    basemap = True\n",
    "except ImportError:\n",
    "    basemap = False\n",
    "\n",
    "\n",
    "def construct_grids(batch):\n",
    "    \"\"\"Construct the map grid from the batch object\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : Batch object\n",
    "        The object returned by :func:`fetch_species_distributions`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (xgrid, ygrid) : 1-D arrays\n",
    "        The grid corresponding to the values in batch.coverages\n",
    "    \"\"\"\n",
    "    # x,y coordinates for corner cells\n",
    "    xmin = batch.x_left_lower_corner + batch.grid_size\n",
    "    xmax = xmin + (batch.Nx * batch.grid_size)\n",
    "    ymin = batch.y_left_lower_corner + batch.grid_size\n",
    "    ymax = ymin + (batch.Ny * batch.grid_size)\n",
    "\n",
    "    # x coordinates of the grid cells\n",
    "    xgrid = np.arange(xmin, xmax, batch.grid_size)\n",
    "    # y coordinates of the grid cells\n",
    "    ygrid = np.arange(ymin, ymax, batch.grid_size)\n",
    "\n",
    "    return (xgrid, ygrid)\n",
    "\n",
    "\n",
    "# Get matrices/arrays of species IDs and locations\n",
    "data = fetch_species_distributions()\n",
    "species_names = ['Bradypus Variegatus', 'Microryzomys Minutus']\n",
    "\n",
    "Xtrain = np.vstack([data['train']['dd lat'],\n",
    "                    data['train']['dd long']]).T\n",
    "ytrain = np.array([d.decode('ascii').startswith('micro')\n",
    "                  for d in data['train']['species']], dtype='int')\n",
    "Xtrain *= np.pi / 180.  # Convert lat/long to radians\n",
    "\n",
    "# Set up the data grid for the contour plot\n",
    "xgrid, ygrid = construct_grids(data)\n",
    "X, Y = np.meshgrid(xgrid[::5], ygrid[::5][::-1])\n",
    "land_reference = data.coverages[6][::5, ::5]\n",
    "land_mask = (land_reference > -9999).ravel()\n",
    "\n",
    "xy = np.vstack([Y.ravel(), X.ravel()]).T\n",
    "xy = xy[land_mask]\n",
    "xy *= np.pi / 180.\n",
    "\n",
    "print(xy)\n",
    "print(xy.shape)\n",
    "\n",
    "# Plot map of South America with distributions of each species\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0.05, right=0.95, wspace=0.05)\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "\n",
    "    # construct a kernel density estimate of the distribution\n",
    "    print(\" - computing KDE in spherical coordinates\")\n",
    "    kde = KernelDensity(bandwidth=0.04, metric='haversine',\n",
    "                        kernel='gaussian', algorithm='ball_tree')\n",
    "    print(Xtrain[ytrain == i])\n",
    "    print(Xtrain[ytrain == i].shape)\n",
    "    kde.fit(Xtrain[ytrain == i])\n",
    "\n",
    "    # evaluate only on the land: -9999 indicates ocean\n",
    "    Z = np.full(land_mask.shape[0], -9999, dtype='int')\n",
    "    Z[land_mask] = np.exp(kde.score_samples(xy))\n",
    "    Z = Z.reshape(X.shape)\n",
    "\n",
    "    # plot contours of the density\n",
    "    levels = np.linspace(0, Z.max(), 25)\n",
    "    plt.contourf(X, Y, Z, levels=levels, cmap=plt.cm.Reds)\n",
    "\n",
    "    if basemap:\n",
    "        print(\" - plot coastlines using basemap\")\n",
    "        m = Basemap(projection='cyl', llcrnrlat=Y.min(),\n",
    "                    urcrnrlat=Y.max(), llcrnrlon=X.min(),\n",
    "                    urcrnrlon=X.max(), resolution='c')\n",
    "        m.drawcoastlines()\n",
    "        m.drawcountries()\n",
    "    else:\n",
    "        print(\" - plot coastlines from coverage\")\n",
    "        plt.contour(X, Y, land_reference,\n",
    "                    levels=[-9998], colors=\"k\",\n",
    "                    linestyles=\"solid\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "    plt.title(species_names[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}